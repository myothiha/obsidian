
[[@TableGPT2024]] proposed a table-tuning approach to fine-tune a vanilla language model on a diverse range of table-related tasks. They introduced 18 table tasks and demonstrated that fine-tuning GPT on varied table tasks, structures, and instructions significantly enhances the modelâ€™s ability to understand table content, achieving higher performance compared to models without table-tuning.